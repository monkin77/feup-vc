{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaU9_sOGzRD1"
      },
      "source": [
        "# Neural Networks\n",
        "In this notebook we will learn how to train a simple Multilayer Perceptron for image classification using PyTorch. You can find additional information [here](https://pytorch.org/tutorials/beginner/basics/intro.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_o30wUG8zRD7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /home/monkin/.local/lib/python3.10/site-packages (2.0.0)\n",
            "Requirement already satisfied: sympy in /home/monkin/.local/lib/python3.10/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/monkin/.local/lib/python3.10/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /home/monkin/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: networkx in /home/monkin/.local/lib/python3.10/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /home/monkin/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: lit in /home/monkin/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: cmake in /home/monkin/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/monkin/.local/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchvision in /home/monkin/.local/lib/python3.10/site-packages (0.15.1)\n",
            "Requirement already satisfied: numpy in /home/monkin/.local/lib/python3.10/site-packages (from torchvision) (1.23.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/monkin/.local/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /home/monkin/.local/lib/python3.10/site-packages (from torchvision) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.0.0->torchvision) (3.6.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: networkx in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.0.0->torchvision) (3.0.3)\n",
            "Requirement already satisfied: sympy in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/monkin/.local/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /home/monkin/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.37.1)\n",
            "Requirement already satisfied: lit in /home/monkin/.local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.2)\n",
            "Requirement already satisfied: cmake in /home/monkin/.local/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.26.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/monkin/.local/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in /home/monkin/.local/lib/python3.10/site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/monkin/.local/lib/python3.10/site-packages (from scikit-learn) (1.23.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/monkin/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/monkin/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in /home/monkin/.local/lib/python3.10/site-packages (4.65.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torchsummary\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install torch\n",
        "! pip install torchvision\n",
        "! pip install scikit-learn\n",
        "! pip install tqdm\n",
        "! pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dvfTDUXuzRD9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBhCwhszREA"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w5IQVCmOzREB"
      },
      "outputs": [],
      "source": [
        "# torchvision has some datasets already included, so we will load MNIST through torchvision\n",
        "# first we need to define the transformations\n",
        "\n",
        "data_aug = transforms.Compose([transforms.ToTensor()]) # the ToTensor transform scales the image into [0., 1.0] range\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "validation_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_aug,\n",
        ")\n",
        "indices = list(range(len(validation_data)))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "test_size = 0.2 * len(indices)\n",
        "split = int(np.floor(test_size))\n",
        "val_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "val_sampler = SubsetRandomSampler(val_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ByDvrH3z1uOT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "5\n",
            "torch.Size([64, 1, 28, 28])\n",
            "tensor([6, 5, 4, 9, 4, 7, 1, 4, 4, 3, 9, 5, 6, 5, 7, 9, 2, 5, 2, 7, 4, 6, 4, 1,\n",
            "        8, 8, 6, 4, 6, 3, 4, 5, 9, 9, 9, 2, 6, 9, 9, 6, 9, 3, 6, 6, 3, 6, 9, 7,\n",
            "        9, 2, 8, 9, 1, 3, 1, 1, 4, 7, 1, 5, 5, 7, 8, 3])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# now we need to define a Dataloader, which allows us to automatically batch our inputs, do sampling and multiprocess data loading\n",
        "batch_size = 64\n",
        "num_workers = 2 # how many processes are used to load the data\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=val_sampler, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "test_dataloader = DataLoader(validation_data, sampler=test_sampler, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "\n",
        "# let's visualize the data\n",
        "# alternative 1: using the Dataset\n",
        "sample = training_data[0] \n",
        "img = sample[0]\n",
        "label = sample[1]\n",
        "print(img.shape) # note that here we only get one image and its label\n",
        "print(label)\n",
        "\n",
        "# alternative 2: iterate over the Dataloader\n",
        "for batch in train_dataloader:\n",
        "  imgs = batch[0]\n",
        "  labels = batch[1]\n",
        "  print(imgs.shape)\n",
        "  print(labels)\n",
        "\n",
        "  plt.imshow(imgs[0][0,:,:], cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqWR_0VzRED"
      },
      "source": [
        "## Defining the model\n",
        "\n",
        "Create an MLP with the following structure: \n",
        "\n",
        "1. Dense/linear layer that takes the images as a flattened input vector and generates an output of 512 of dimension.\n",
        "2. ReLU activation layer\n",
        "3. Dense/linear layer with 512 input and output\n",
        "3. ReLU activation layer\n",
        "4. Dense/linear layer with 10 output channels (10 classes of MNIST)\n",
        "\n",
        "You can use PyTorch's layers: https://pytorch.org/docs/stable/nn.html (Conv2d, ReLU, Linear, MaxPool2d, Dropout, Flatten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DfK3c9RSzRED"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # TODO \n",
        "        # Flattened image has size 28*28=784\n",
        "        flattenedImgSize = 28*28\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(flattenedImgSize, 512),   # Number of parameters: 28*28*512 + 512 (bias) = 401,920\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),    # Number of parameters: 512*512 + 512 (bias) = 262,656\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),     # Number of parameters: 512*10 + 10 (bias) = 5,130\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "         # TODO \n",
        "        \n",
        "        \n",
        "\n",
        "model = NeuralNetwork().to(device) # put model in device (GPU or CPU)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpret the implemented architecture and try to answer the following questions:\n",
        "\n",
        "a) What is the shape (width, and # of channels) of the output tensor after the first layer?\n",
        "\n",
        "Shape = (512, 1)\n",
        "\n",
        "\n",
        "b) And after the first 3 layers (dense+dense+dense)?\n",
        "\n",
        "Shape = (10, 1)\n",
        "\n",
        "c) How many parameters (weights) does the model have? Contrary to Keras, PyTorch does not have an official method for counting the number of parameters of a model, but you can use [torchsummary](https://pypi.org/project/torch-summary/)\n",
        "\n",
        "Number of parameters = 401,920 + 262,656 + 5,130 = 669,706"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install torch-summary\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g1kRGiw_zREE"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Define:\n",
        "1. The loss function\n",
        "2. The optimiser \n",
        "3. The training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO\n",
        "# loss_fn = ...\n",
        "# optimizer = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxSdayviCWk5"
      },
      "outputs": [],
      "source": [
        "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
        "    if is_train:\n",
        "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
        "      \n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    if is_train:\n",
        "      model.train() # put model in train mode\n",
        "    else:\n",
        "      model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # TODO: Compute prediction error\n",
        "          # pred = ...\n",
        "          # loss = ...\n",
        "\n",
        "          if is_train:\n",
        "            # TODO: Backpropagation\n",
        "\n",
        "          # TODO: Compute final prediction (softmax + argmax)\n",
        "          # probs = ...\n",
        "          # final_pred = ...\n",
        "\n",
        "          # Save training metrics\n",
        "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
        "\n",
        "          preds.extend(final_pred.cpu().numpy())\n",
        "          labels.extend(y.cpu().numpy())\n",
        "\n",
        "    return total_loss / num_batches, accuracy_score(labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmsUVGS6C0O1"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "train_history = {'loss': [], 'accuracy': []}\n",
        "val_history = {'loss': [], 'accuracy': []}\n",
        "best_val_loss = np.inf\n",
        "print(\"Start training...\")\n",
        "for t in range(num_epochs):\n",
        "    print(f\"\\nEpoch {t+1}\")\n",
        "    train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
        "    print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
        "    val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
        "    print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
        "\n",
        "    # save model when val loss improves\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "      torch.save(save_dict, 'best_model.pth')\n",
        "\n",
        "    # save latest model\n",
        "    save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
        "    torch.save(save_dict, 'latest_model.pth')\n",
        "\n",
        "    # save training history for plotting purposes\n",
        "    train_history[\"loss\"].append(train_loss)\n",
        "    train_history[\"accuracy\"].append(train_acc)\n",
        "\n",
        "    val_history[\"loss\"].append(val_loss)\n",
        "    val_history[\"accuracy\"].append(val_acc)\n",
        "    \n",
        "print(\"Finished\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrQMAKFHzREG"
      },
      "source": [
        "## Analyse training evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr48TEVlzREH"
      },
      "outputs": [],
      "source": [
        "def plotTrainingHistory(train_history, val_history):\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(train_history['loss'], label='train')\n",
        "    plt.plot(val_history['loss'], label='val')\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(train_history['accuracy'], label='train')\n",
        "    plt.plot(val_history['accuracy'], label='val')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GfeNPc4zREI"
      },
      "outputs": [],
      "source": [
        "plotTrainingHistory(train_history, val_history)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HPZLw5cfzREI"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "Evaluate the model in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtmFHipizREK"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1yyEC9pzREJ"
      },
      "outputs": [],
      "source": [
        "def showErrors(model, dataloader, num_examples=20):    \n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    for ind, (X, y) in enumerate(dataloader):\n",
        "      if ind >= 20: break\n",
        "      X, y = X.to(device), y.to(device)    \n",
        "      pred = model(X)\n",
        "      probs = F.softmax(pred, dim=1)\n",
        "      final_pred = torch.argmax(probs, dim=1)\n",
        "\n",
        "      plt.subplot(10, 10, ind + 1)\n",
        "      plt.axis(\"off\")\n",
        "      plt.text(0, -1, y[0].item(), fontsize=14, color='green') # correct\n",
        "      plt.text(8, -1, final_pred[0].item(), fontsize=14, color='red')  # predicted\n",
        "      plt.imshow(X[0][0,:,:].cpu(), cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh38evzTzREL"
      },
      "outputs": [],
      "source": [
        "showErrors(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-C6glKseuO"
      },
      "source": [
        "## Additional Challenges\n",
        "\n",
        "a) As the test accuracy should show, the MNIST dataset is not very challenging, change the code to use Fashion-MNIST and compare the results.\n",
        "\n",
        "b) Do the same for the CIFAR10 (or CIFAR100) dataset. Note that, in this case, each image is a 32x32 color image; convert it to grayscale or concatenate the RGB channels in one single vector (e.g. using the reshape method).\n",
        "\n",
        "c) The test accuracy for CIFAR is significantly worse. Try improving the results by using: 1) a deeper architecture, and 2) a different optmizer.\n",
        "\n",
        "You can load the datasets from [here](https://pytorch.org/vision/stable/datasets.html).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nn_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "6f87761e9bbb4702bed86fcb6eaee0e223d39ee952a340c687ff9c7dfa805330"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
